{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e97b24fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from  sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7402200f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/flowerbed/Desktop/School/9th Grade 2020 - 2021/2021 UCSF AI4ALL/GitHub/ai4all_nhanes/env/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3441: DtypeWarning: Columns (600,601) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DPQ010</th>\n",
       "      <th>DPQ020</th>\n",
       "      <th>DPQ030</th>\n",
       "      <th>DPQ040</th>\n",
       "      <th>DPQ050</th>\n",
       "      <th>DPQ060</th>\n",
       "      <th>DPQ070</th>\n",
       "      <th>DPQ080</th>\n",
       "      <th>DPQ090</th>\n",
       "      <th>DPQ100</th>\n",
       "      <th>labels_raw</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEQN</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62161.0</th>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62169.0</th>\n",
       "      <td>several days</td>\n",
       "      <td>not at all</td>\n",
       "      <td>several days</td>\n",
       "      <td>several days</td>\n",
       "      <td>several days</td>\n",
       "      <td>more than half the days</td>\n",
       "      <td>not at all</td>\n",
       "      <td>several days</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62172.0</th>\n",
       "      <td>several days</td>\n",
       "      <td>more than half the days</td>\n",
       "      <td>several days</td>\n",
       "      <td>several days</td>\n",
       "      <td>several days</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>several days</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62174.0</th>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62176.0</th>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93691.0</th>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93695.0</th>\n",
       "      <td>not at all</td>\n",
       "      <td>several days</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>more than half the days</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93696.0</th>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93697.0</th>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93702.0</th>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>several days</td>\n",
       "      <td>several days</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>not at all</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15513 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               DPQ010                   DPQ020        DPQ030        DPQ040  \\\n",
       "SEQN                                                                         \n",
       "62161.0    not at all               not at all    not at all    not at all   \n",
       "62169.0  several days               not at all  several days  several days   \n",
       "62172.0  several days  more than half the days  several days  several days   \n",
       "62174.0    not at all               not at all    not at all    not at all   \n",
       "62176.0    not at all               not at all    not at all    not at all   \n",
       "...               ...                      ...           ...           ...   \n",
       "93691.0    not at all               not at all    not at all    not at all   \n",
       "93695.0    not at all             several days    not at all    not at all   \n",
       "93696.0    not at all               not at all    not at all    not at all   \n",
       "93697.0    not at all               not at all    not at all    not at all   \n",
       "93702.0    not at all               not at all  several days  several days   \n",
       "\n",
       "               DPQ050                   DPQ060      DPQ070        DPQ080  \\\n",
       "SEQN                                                                       \n",
       "62161.0    not at all               not at all  not at all    not at all   \n",
       "62169.0  several days  more than half the days  not at all  several days   \n",
       "62172.0  several days               not at all  not at all    not at all   \n",
       "62174.0    not at all               not at all  not at all    not at all   \n",
       "62176.0    not at all               not at all  not at all    not at all   \n",
       "...               ...                      ...         ...           ...   \n",
       "93691.0    not at all               not at all  not at all    not at all   \n",
       "93695.0    not at all               not at all  not at all    not at all   \n",
       "93696.0    not at all               not at all  not at all    not at all   \n",
       "93697.0    not at all               not at all  not at all    not at all   \n",
       "93702.0    not at all               not at all  not at all    not at all   \n",
       "\n",
       "             DPQ090                   DPQ100  labels_raw  labels  \n",
       "SEQN                                                              \n",
       "62161.0  not at all               not at all           0       0  \n",
       "62169.0  not at all               not at all           7       0  \n",
       "62172.0  not at all             several days           7       0  \n",
       "62174.0  not at all               not at all           0       0  \n",
       "62176.0  not at all               not at all           0       0  \n",
       "...             ...                      ...         ...     ...  \n",
       "93691.0  not at all               not at all           0       0  \n",
       "93695.0  not at all  more than half the days           3       0  \n",
       "93696.0  not at all               not at all           0       0  \n",
       "93697.0  not at all               not at all           0       0  \n",
       "93702.0  not at all               not at all           2       0  \n",
       "\n",
       "[15513 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_df = pd.read_csv('all_data_df.csv')\n",
    "all_data_df.index = all_data_df['SEQN']\n",
    "\n",
    "mental_health_df = all_data_df.loc[:, 'DPQ010':'DPQ100'].dropna(how='all')\n",
    "all_data_df = all_data_df.loc[mental_health_df.index]\n",
    "\n",
    "def mh(x):\n",
    "    if x == '\\.':\n",
    "        return 'missing'\n",
    "    elif x == 1:\n",
    "        return 'several days'\n",
    "    elif x == 2:\n",
    "        return 'more than half the days'\n",
    "    elif x == 3:\n",
    "        return 'nearly every day'\n",
    "    elif x == 7:\n",
    "        return 'refused'\n",
    "    elif x == 9:\n",
    "        return \"don't know\"\n",
    "    else:\n",
    "        return 'not at all'\n",
    "\n",
    "for col in mental_health_df.columns:\n",
    "    mental_health_df[col] = mental_health_df[col].apply(lambda x: mh(x))\n",
    "    \n",
    "def calc(row):\n",
    "    sum = 0\n",
    "    for i in ['DPQ010', 'DPQ020', 'DPQ030', 'DPQ040', \n",
    "              'DPQ050', 'DPQ060', 'DPQ070','DPQ080', \n",
    "              'DPQ090', 'DPQ100']:\n",
    "        if row[i] == 'several days':\n",
    "            sum += 1\n",
    "        if row[i] == 'more than half the days':\n",
    "            sum += 2\n",
    "        if row[i] == 'nearly every day':\n",
    "            sum += 3\n",
    "    return sum\n",
    "\n",
    "mental_health_df['labels_raw'] = mental_health_df.apply(calc, axis=1)\n",
    "mental_health_df['labels'] = mental_health_df['labels_raw'].apply(lambda x: 1 if x >= 10 else 0)\n",
    "\n",
    "mental_health_df.to_csv('mental_health_df.csv')\n",
    "mental_health_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7817cb38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [\n",
    "    #diabetes\n",
    "    'DIQ010','DID040','DIQ160','DIQ170','DIQ172','DIQ175A','DIQ175B','DIQ175C',\n",
    "    'DIQ175D','DIQ175E','DIQ175F','DIQ175G','DIQ175H','DIQ175I','DIQ175J','DIQ175K',\n",
    "    'DIQ175L', 'DIQ175M','DIQ175N','DIQ175O','DIQ175P','DIQ175Q','DIQ175R','DIQ175S',\n",
    "    'DIQ175T','DIQ175U','DIQ175V','DIQ175W','DIQ180','DIQ050','DID060','DIQ060U',\n",
    "    'DIQ070','DIQ230','DIQ240','DID250','DID260','DIQ260U','DIQ275','DIQ280','DIQ291',\n",
    "    'DIQ300S','DIQ300D','DID310S','DID310D','DID320','DID330','DID341','DID350',\n",
    "    'DIQ350U','DIQ360','DIQ080', \n",
    "    #sleep disorder\n",
    "    'SLQ050', \n",
    "    #physical activity\n",
    "    'PAQ605','PAQ610','PAD615','PAQ620','PAQ625','PAD630','PAQ635','PAQ640','PAD645',\n",
    "    'PAQ650','PAQ655','PAD660','PAQ665','PAQ670','PAD675','PAD680','PAQ706','PAQ710',\n",
    "    'PAQ715', \n",
    "    #weight history\n",
    "    'WHD010','WHD020','WHQ030','WHQ040','WHD050','WHQ060','WHQ070','WHD080A','WHD080B',\n",
    "    'WHD080C','WHD080D','WHD080E','WHD080F','WHD080G','WHD080H','WHD080I','WHD080J',\n",
    "    'WHD080K','WHD080M','WHD080N','WHD080O','WHD080P','WHD080Q','WHD080R','WHD080S',\n",
    "    'WHD080T','WHD080L','WHD110','WHD120','WHD130','WHD140','WHQ150', \n",
    "    #early childhood\n",
    "    'ECD010','ECQ020','ECD070A','ECD070B','ECQ080','ECQ090','WHQ030E','MCQ080E',\n",
    "    'ECQ150', \n",
    "    #alcohol issues\n",
    "    'ALQ101','ALQ110','ALQ120Q','ALQ120U','ALQ130','ALQ141Q','ALQ141U','ALQ151',\n",
    "    #hospital access\n",
    "    'HUQ010','HUQ020','HUQ030','HUQ071','HUD080','HUQ090', \n",
    "    #health status\n",
    "    'HSD010','HSQ500','HSQ510','HSQ520','HSQ571','HSQ580','HSQ590','HSAQUEX',  \n",
    "    #income\n",
    "    #housing\n",
    "    'HOD050','HOQ065', \n",
    "    #occupation\n",
    "    'OCD150','OCQ180','OCQ210','OCQ260','OCD270','OCQ380','OCD390G','OCD395', \n",
    "    #mental health\n",
    "    #demographic\n",
    "    #diet nutrition\n",
    "    'DBQ010','DBD030','DBD041','DBD050','DBD055','DBD061','DBQ073A','DBQ073B','DBQ073C',\n",
    "    'DBQ073D','DBQ073E','DBQ073U','DBQ700','DBQ197','DBQ223A','DBQ223B','DBQ223C',\n",
    "    'DBQ223D','DBQ223E','DBQ223U','DBQ229','DBQ235A','DBQ235B','DBQ235C','DBQ301',\n",
    "    'DBQ330','DBQ360','DBQ370','DBD381','DBQ390','DBQ400','DBD411','DBQ421','DBQ424',\n",
    "    'DBD895','DBD900','DBD905','DBD910', \n",
    "    #drug use\n",
    "    'DUQ200','DUQ210','DUQ211','DUQ213','DUQ215Q','DUQ215U','DUQ217','DUQ219','DUQ220Q',\n",
    "    'DUQ220U','DUQ230','DUQ240','DUQ250','DUQ260','DUQ270Q','DUQ270U','DUQ272','DUQ280',\n",
    "    'DUQ290','DUQ300','DUQ310Q','DUQ310U','DUQ320','DUQ330','DUQ340','DUQ350Q','DUQ350U',\n",
    "    'DUQ352','DUQ360','DUQ370','DUQ380A','DUQ380B','DUQ380C','DUQ380D','DUQ380E',\n",
    "    'DUQ390','DUQ400Q','DUQ400U','DUQ410','DUQ420', \n",
    "    \n",
    "]\n",
    "\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4e18aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = all_data_df[features]\n",
    "y = mental_health_df['labels']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78765c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n",
       "                ('enc', OneHotEncoder(handle_unknown='ignore', sparse=False)),\n",
       "                ('red', PCA(n_components=10)), ('clf', GaussianNB())])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('enc', OneHotEncoder(sparse=False, handle_unknown='ignore')), \n",
    "    ('red', PCA(n_components=10)),\n",
    "    ('clf', GaussianNB())\n",
    "])\n",
    "nb_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f7ffb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7645128084586452\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.762133452070479"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_training_score = roc_auc_score(y_train.values, nb_pipe.predict_proba(X_train)[:, 1])\n",
    "nb_validation_score = roc_auc_score(y_val.values, nb_pipe.predict_proba(X_val)[:, 1])\n",
    "print(nb_training_score)\n",
    "nb_validation_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15dcb7d",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4745798d",
   "metadata": {},
   "source": [
    "### Round 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b88a232c",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = permutation_importance(\n",
    "    nb_pipe, \n",
    "    X_val, \n",
    "    y_val,\n",
    "    n_repeats=10,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6364d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance_means</th>\n",
       "      <th>importances_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DBQ700</th>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAD645</th>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIQ080</th>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WHD020</th>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HSQ520</th>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HSD010</th>\n",
       "      <td>-0.001870</td>\n",
       "      <td>0.000787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIQ230</th>\n",
       "      <td>-0.001934</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HUQ010</th>\n",
       "      <td>-0.002128</td>\n",
       "      <td>0.000709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OCD150</th>\n",
       "      <td>-0.002192</td>\n",
       "      <td>0.000875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DUQ240</th>\n",
       "      <td>-0.002515</td>\n",
       "      <td>0.000193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>223 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        importance_means  importances_std\n",
       "DBQ700          0.000129         0.000258\n",
       "PAD645          0.000129         0.000258\n",
       "DIQ080          0.000064         0.000193\n",
       "WHD020          0.000064         0.000193\n",
       "HSQ520          0.000064         0.000193\n",
       "...                  ...              ...\n",
       "HSD010         -0.001870         0.000787\n",
       "DIQ230         -0.001934         0.000000\n",
       "HUQ010         -0.002128         0.000709\n",
       "OCD150         -0.002192         0.000875\n",
       "DUQ240         -0.002515         0.000193\n",
       "\n",
       "[223 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        'importance_means': r['importances_mean'],\n",
    "        'importances_std': r['importances_std']\n",
    "    }, orient='columns'\n",
    ")\n",
    "feature_importances.index = X_val.columns\n",
    "\n",
    "feature_importances.sort_values('importance_means', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21fdf64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['DIQ010',\n",
       " 'DID040',\n",
       " 'DIQ160',\n",
       " 'DIQ172',\n",
       " 'DIQ175A',\n",
       " 'DIQ175B',\n",
       " 'DIQ175C',\n",
       " 'DIQ175D',\n",
       " 'DIQ175E',\n",
       " 'DIQ175F',\n",
       " 'DIQ175G',\n",
       " 'DIQ175H',\n",
       " 'DIQ175I',\n",
       " 'DIQ175J',\n",
       " 'DIQ175K',\n",
       " 'DIQ175L',\n",
       " 'DIQ175M',\n",
       " 'DIQ175N',\n",
       " 'DIQ175O',\n",
       " 'DIQ175P',\n",
       " 'DIQ175Q',\n",
       " 'DIQ175R',\n",
       " 'DIQ175S',\n",
       " 'DIQ175T',\n",
       " 'DIQ175U',\n",
       " 'DIQ175V',\n",
       " 'DIQ175W',\n",
       " 'DIQ180',\n",
       " 'DIQ050',\n",
       " 'DID060',\n",
       " 'DIQ060U',\n",
       " 'DIQ070',\n",
       " 'DIQ230',\n",
       " 'DIQ240',\n",
       " 'DID250',\n",
       " 'DID260',\n",
       " 'DIQ260U',\n",
       " 'DIQ275',\n",
       " 'DIQ280',\n",
       " 'DIQ291',\n",
       " 'DIQ300S',\n",
       " 'DIQ300D',\n",
       " 'DID310S',\n",
       " 'DID310D',\n",
       " 'DID320',\n",
       " 'DID330',\n",
       " 'DID341',\n",
       " 'DID350',\n",
       " 'DIQ350U',\n",
       " 'DIQ360',\n",
       " 'SLQ050',\n",
       " 'PAQ610',\n",
       " 'PAD615',\n",
       " 'PAD630',\n",
       " 'PAQ635',\n",
       " 'PAQ650',\n",
       " 'PAQ655',\n",
       " 'PAD660',\n",
       " 'PAQ665',\n",
       " 'PAQ670',\n",
       " 'PAD680',\n",
       " 'PAQ706',\n",
       " 'PAQ710',\n",
       " 'WHQ040',\n",
       " 'WHQ060',\n",
       " 'WHQ070',\n",
       " 'WHD080A',\n",
       " 'WHD080B',\n",
       " 'WHD080C',\n",
       " 'WHD080D',\n",
       " 'WHD080E',\n",
       " 'WHD080F',\n",
       " 'WHD080G',\n",
       " 'WHD080H',\n",
       " 'WHD080I',\n",
       " 'WHD080J',\n",
       " 'WHD080K',\n",
       " 'WHD080M',\n",
       " 'WHD080N',\n",
       " 'WHD080O',\n",
       " 'WHD080P',\n",
       " 'WHD080Q',\n",
       " 'WHD080R',\n",
       " 'WHD080S',\n",
       " 'WHD080T',\n",
       " 'WHD080L',\n",
       " 'WHD120',\n",
       " 'WHD130',\n",
       " 'WHQ150',\n",
       " 'ECD010',\n",
       " 'ECQ020',\n",
       " 'ECD070A',\n",
       " 'ECD070B',\n",
       " 'ECQ080',\n",
       " 'ECQ090',\n",
       " 'WHQ030E',\n",
       " 'MCQ080E',\n",
       " 'ECQ150',\n",
       " 'ALQ120U',\n",
       " 'ALQ130',\n",
       " 'ALQ141Q',\n",
       " 'ALQ141U',\n",
       " 'ALQ151',\n",
       " 'HUQ010',\n",
       " 'HUQ030',\n",
       " 'HUQ071',\n",
       " 'HUD080',\n",
       " 'HUQ090',\n",
       " 'HSD010',\n",
       " 'HSQ571',\n",
       " 'HSQ580',\n",
       " 'HSQ590',\n",
       " 'HSAQUEX',\n",
       " 'OCD150',\n",
       " 'OCQ180',\n",
       " 'OCQ210',\n",
       " 'OCD270',\n",
       " 'OCQ380',\n",
       " 'OCD395',\n",
       " 'DBQ010',\n",
       " 'DBD030',\n",
       " 'DBD041',\n",
       " 'DBD050',\n",
       " 'DBD055',\n",
       " 'DBD061',\n",
       " 'DBQ073A',\n",
       " 'DBQ073B',\n",
       " 'DBQ073C',\n",
       " 'DBQ073D',\n",
       " 'DBQ073E',\n",
       " 'DBQ073U',\n",
       " 'DBQ223A',\n",
       " 'DBQ223B',\n",
       " 'DBQ223C',\n",
       " 'DBQ223D',\n",
       " 'DBQ223E',\n",
       " 'DBQ223U',\n",
       " 'DBQ229',\n",
       " 'DBQ235A',\n",
       " 'DBQ235C',\n",
       " 'DBQ301',\n",
       " 'DBQ330',\n",
       " 'DBQ360',\n",
       " 'DBQ370',\n",
       " 'DBD381',\n",
       " 'DBQ390',\n",
       " 'DBQ400',\n",
       " 'DBD411',\n",
       " 'DBQ421',\n",
       " 'DBQ424',\n",
       " 'DBD900',\n",
       " 'DBD905',\n",
       " 'DUQ200',\n",
       " 'DUQ210',\n",
       " 'DUQ211',\n",
       " 'DUQ213',\n",
       " 'DUQ215Q',\n",
       " 'DUQ215U',\n",
       " 'DUQ217',\n",
       " 'DUQ219',\n",
       " 'DUQ220Q',\n",
       " 'DUQ220U',\n",
       " 'DUQ230',\n",
       " 'DUQ240',\n",
       " 'DUQ250',\n",
       " 'DUQ260',\n",
       " 'DUQ270Q',\n",
       " 'DUQ270U',\n",
       " 'DUQ272',\n",
       " 'DUQ280',\n",
       " 'DUQ290',\n",
       " 'DUQ300',\n",
       " 'DUQ310Q',\n",
       " 'DUQ310U',\n",
       " 'DUQ320',\n",
       " 'DUQ330',\n",
       " 'DUQ340',\n",
       " 'DUQ350Q',\n",
       " 'DUQ350U',\n",
       " 'DUQ352',\n",
       " 'DUQ360',\n",
       " 'DUQ370',\n",
       " 'DUQ380A',\n",
       " 'DUQ380B',\n",
       " 'DUQ380C',\n",
       " 'DUQ380D',\n",
       " 'DUQ380E',\n",
       " 'DUQ390',\n",
       " 'DUQ400Q',\n",
       " 'DUQ400U',\n",
       " 'DUQ410',\n",
       " 'DUQ420']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove = []\n",
    "\n",
    "for feature in feature_importances[\n",
    "    (feature_importances['importance_means'] <= 0) & \n",
    "    (abs(feature_importances['importance_means']) >= feature_importances['importances_std'])\n",
    "].index:\n",
    "    # print(feature)\n",
    "    remove.append(feature)\n",
    "\n",
    "print(len(remove))\n",
    "remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0c20392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['DIQ170',\n",
       " 'DIQ080',\n",
       " 'PAQ605',\n",
       " 'PAQ620',\n",
       " 'PAQ625',\n",
       " 'PAQ640',\n",
       " 'PAD645',\n",
       " 'PAD675',\n",
       " 'PAQ715',\n",
       " 'WHD010',\n",
       " 'WHD020',\n",
       " 'WHQ030',\n",
       " 'WHD050',\n",
       " 'WHD110',\n",
       " 'WHD140',\n",
       " 'ALQ101',\n",
       " 'ALQ110',\n",
       " 'ALQ120Q',\n",
       " 'HUQ020',\n",
       " 'HSQ500',\n",
       " 'HSQ510',\n",
       " 'HSQ520',\n",
       " 'HOD050',\n",
       " 'HOQ065',\n",
       " 'OCQ260',\n",
       " 'OCD390G',\n",
       " 'DBQ700',\n",
       " 'DBQ197',\n",
       " 'DBQ235B',\n",
       " 'DBD895',\n",
       " 'DBD910']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for feature in remove:\n",
    "    features.remove(feature)\n",
    "\n",
    "print(len(features))\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d7e6495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.709253251157018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6926540478159331"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = all_data_df[features]\n",
    "y = mental_health_df['labels']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "nb_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('enc', OneHotEncoder(sparse=False, handle_unknown='ignore')), \n",
    "    ('red', PCA(n_components=10)),\n",
    "    ('clf', GaussianNB())\n",
    "])\n",
    "nb_pipe.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "nb_training_score = roc_auc_score(y_train.values, nb_pipe.predict_proba(X_train)[:, 1])\n",
    "nb_validation_score = roc_auc_score(y_val.values, nb_pipe.predict_proba(X_val)[:, 1])\n",
    "print(nb_training_score)\n",
    "nb_validation_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb8fff8",
   "metadata": {},
   "source": [
    "### Round 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c501745f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['DIQ170',\n",
       " 'DIQ080',\n",
       " 'PAQ605',\n",
       " 'PAQ620',\n",
       " 'PAQ625',\n",
       " 'PAQ640',\n",
       " 'PAD645',\n",
       " 'PAD675',\n",
       " 'PAQ715',\n",
       " 'WHD010',\n",
       " 'WHD020',\n",
       " 'WHQ030',\n",
       " 'WHD050',\n",
       " 'WHD110',\n",
       " 'WHD140',\n",
       " 'ALQ101',\n",
       " 'ALQ110',\n",
       " 'ALQ120Q',\n",
       " 'HSQ500',\n",
       " 'HSQ510',\n",
       " 'HSQ520',\n",
       " 'HOD050',\n",
       " 'HOQ065',\n",
       " 'OCQ260',\n",
       " 'DBQ197',\n",
       " 'DBQ235B',\n",
       " 'DBD895',\n",
       " 'DBD910']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = permutation_importance(\n",
    "    nb_pipe, \n",
    "    X_val, \n",
    "    y_val,\n",
    "    n_repeats=10,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "feature_importances = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        'importance_means': r['importances_mean'],\n",
    "        'importances_std': r['importances_std']\n",
    "    }, orient='columns'\n",
    ")\n",
    "feature_importances.index = X_val.columns\n",
    "\n",
    "#feature_importances.sort_values('importance_means', ascending = False)\n",
    "\n",
    "\n",
    "remove = []\n",
    "\n",
    "for feature in feature_importances[\n",
    "    (feature_importances['importance_means'] <= 0) & \n",
    "    (abs(feature_importances['importance_means']) >= feature_importances['importances_std'])\n",
    "].index:\n",
    "    # print(feature)\n",
    "    remove.append(feature)\n",
    "\n",
    "print(len(remove))\n",
    "remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558ba620",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24d3eb43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['HUQ020', 'OCD390G', 'DBQ700']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for feature in remove:\n",
    "    features.remove(feature)\n",
    "\n",
    "print(len(features))\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b36694c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing python to see if remove works properly\n",
    "l = ['hello', 'hi', 'howdy']\n",
    "print(l)\n",
    "r = ['hello']\n",
    "print(r)\n",
    "\n",
    "for i in r:\n",
    "    l.remove(i)\n",
    "\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f684c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7055753605927085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7074409116104938"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = all_data_df[features]\n",
    "y = mental_health_df['labels']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "nb_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('enc', OneHotEncoder(sparse=False, handle_unknown='ignore')), \n",
    "    ('red', PCA(n_components=10)),\n",
    "    ('clf', GaussianNB())\n",
    "])\n",
    "nb_pipe.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "nb_training_score = roc_auc_score(y_train.values, nb_pipe.predict_proba(X_train)[:, 1])\n",
    "nb_validation_score = roc_auc_score(y_val.values, nb_pipe.predict_proba(X_val)[:, 1])\n",
    "print(nb_training_score)\n",
    "nb_validation_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd31d642",
   "metadata": {},
   "source": [
    "### Round 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e7d2ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['OCD390G']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = permutation_importance(\n",
    "    nb_pipe, \n",
    "    X_val, \n",
    "    y_val,\n",
    "    n_repeats=10,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "feature_importances = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        'importance_means': r['importances_mean'],\n",
    "        'importances_std': r['importances_std']\n",
    "    }, orient='columns'\n",
    ")\n",
    "feature_importances.index = X_val.columns\n",
    "\n",
    "#feature_importances.sort_values('importance_means', ascending = False)\n",
    "\n",
    "\n",
    "remove = []\n",
    "\n",
    "for feature in feature_importances[\n",
    "    (feature_importances['importance_means'] <= 0) & \n",
    "    (abs(feature_importances['importance_means']) >= feature_importances['importances_std'])\n",
    "].index:\n",
    "    # print(feature)\n",
    "    remove.append(feature)\n",
    "\n",
    "print(len(remove))\n",
    "remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2257ac5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['HUQ020', 'DBQ700']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for feature in remove:\n",
    "    features.remove(feature)\n",
    "\n",
    "print(len(features))\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8d97f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6827450551602064\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6887784310340127"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = all_data_df[features]\n",
    "y = mental_health_df['labels']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "nb_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('enc', OneHotEncoder(sparse=False, handle_unknown='ignore')), \n",
    "    ('red', PCA(n_components=10)),\n",
    "    ('clf', GaussianNB())\n",
    "])\n",
    "nb_pipe.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "nb_training_score = roc_auc_score(y_train.values, nb_pipe.predict_proba(X_train)[:, 1])\n",
    "nb_validation_score = roc_auc_score(y_val.values, nb_pipe.predict_proba(X_val)[:, 1])\n",
    "print(nb_training_score)\n",
    "nb_validation_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300f0f30",
   "metadata": {},
   "source": [
    "### Round 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78d5fdef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['HUQ020']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = permutation_importance(\n",
    "    nb_pipe, \n",
    "    X_val, \n",
    "    y_val,\n",
    "    n_repeats=10,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "feature_importances = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        'importance_means': r['importances_mean'],\n",
    "        'importances_std': r['importances_std']\n",
    "    }, orient='columns'\n",
    ")\n",
    "feature_importances.index = X_val.columns\n",
    "\n",
    "#feature_importances.sort_values('importance_means', ascending = False)\n",
    "\n",
    "\n",
    "remove = []\n",
    "\n",
    "for feature in feature_importances[\n",
    "    (feature_importances['importance_means'] <= 0) & \n",
    "    (abs(feature_importances['importance_means']) >= feature_importances['importances_std'])\n",
    "].index:\n",
    "    # print(feature)\n",
    "    remove.append(feature)\n",
    "\n",
    "print(len(remove))\n",
    "remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c0995b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['DBQ700']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for feature in remove:\n",
    "    features.remove(feature)\n",
    "\n",
    "print(len(features))\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab31d959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6469248647159435\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6493566385271748"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = all_data_df[features]\n",
    "y = mental_health_df['labels']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "nb_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('enc', OneHotEncoder(sparse=False, handle_unknown='ignore')), \n",
    "    ('red', PCA(n_components=5)),\n",
    "    ('clf', GaussianNB())\n",
    "])\n",
    "nb_pipe.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "nb_training_score = roc_auc_score(y_train.values, nb_pipe.predict_proba(X_train)[:, 1])\n",
    "nb_validation_score = roc_auc_score(y_val.values, nb_pipe.predict_proba(X_val)[:, 1])\n",
    "print(nb_training_score)\n",
    "nb_validation_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a804d8b1",
   "metadata": {},
   "source": [
    "### Round 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1cdd7dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = permutation_importance(\n",
    "    nb_pipe, \n",
    "    X_val, \n",
    "    y_val,\n",
    "    n_repeats=10,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "feature_importances = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        'importance_means': r['importances_mean'],\n",
    "        'importances_std': r['importances_std']\n",
    "    }, orient='columns'\n",
    ")\n",
    "feature_importances.index = X_val.columns\n",
    "\n",
    "#feature_importances.sort_values('importance_means', ascending = False)\n",
    "\n",
    "\n",
    "remove = []\n",
    "\n",
    "for feature in feature_importances[\n",
    "    (feature_importances['importance_means'] <= 0) & \n",
    "    (abs(feature_importances['importance_means']) >= feature_importances['importances_std'])\n",
    "].index:\n",
    "    # print(feature)\n",
    "    remove.append(feature)\n",
    "\n",
    "print(len(remove))\n",
    "remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0c6b9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['DBQ700']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for feature in remove:\n",
    "    features.remove(feature)\n",
    "\n",
    "print(len(features))\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e3a02617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6469248647159435\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6493566385271748"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = all_data_df[features]\n",
    "y = mental_health_df['labels']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "nb_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('enc', OneHotEncoder(sparse=False, handle_unknown='ignore')), \n",
    "    ('red', PCA(n_components=6)),\n",
    "    ('clf', GaussianNB())\n",
    "])\n",
    "nb_pipe.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "nb_training_score = roc_auc_score(y_train.values, nb_pipe.predict_proba(X_train)[:, 1])\n",
    "nb_validation_score = roc_auc_score(y_val.values, nb_pipe.predict_proba(X_val)[:, 1])\n",
    "print(nb_training_score)\n",
    "nb_validation_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586b8410",
   "metadata": {},
   "source": [
    "### Round 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6cfc9f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = permutation_importance(\n",
    "    nb_pipe, \n",
    "    X_val, \n",
    "    y_val,\n",
    "    n_repeats=10,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "feature_importances = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        'importance_means': r['importances_mean'],\n",
    "        'importances_std': r['importances_std']\n",
    "    }, orient='columns'\n",
    ")\n",
    "feature_importances.index = X_val.columns\n",
    "\n",
    "#feature_importances.sort_values('importance_means', ascending = False)\n",
    "\n",
    "\n",
    "remove = []\n",
    "\n",
    "for feature in feature_importances[\n",
    "    (feature_importances['importance_means'] <= 0) & \n",
    "    (abs(feature_importances['importance_means']) >= feature_importances['importances_std'])\n",
    "].index:\n",
    "    # print(feature)\n",
    "    remove.append(feature)\n",
    "\n",
    "print(len(remove))\n",
    "remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "77dfb4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['DBQ700']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for feature in remove:\n",
    "    features.remove(feature)\n",
    "\n",
    "print(len(features))\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72c3f945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6469248647159435\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6493566385271748"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = all_data_df[features]\n",
    "y = mental_health_df['labels']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "nb_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('enc', OneHotEncoder(sparse=False, handle_unknown='ignore')), \n",
    "    ('red', PCA(n_components=5)),\n",
    "    ('clf', GaussianNB())\n",
    "])\n",
    "nb_pipe.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "nb_training_score = roc_auc_score(y_train.values, nb_pipe.predict_proba(X_train)[:, 1])\n",
    "nb_validation_score = roc_auc_score(y_val.values, nb_pipe.predict_proba(X_val)[:, 1])\n",
    "print(nb_training_score)\n",
    "nb_validation_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea62e09e",
   "metadata": {},
   "source": [
    "## Not in Use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89b74d7",
   "metadata": {},
   "source": [
    "### Round 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a97f761",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = permutation_importance(\n",
    "    nb_pipe, \n",
    "    X_val, \n",
    "    y_val,\n",
    "    n_repeats=10,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "feature_importances = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        'importance_means': r['importances_mean'],\n",
    "        'importances_std': r['importances_std']\n",
    "    }, orient='columns'\n",
    ")\n",
    "feature_importances.index = X_val.columns\n",
    "\n",
    "#feature_importances.sort_values('importance_means', ascending = False)\n",
    "\n",
    "\n",
    "remove = []\n",
    "\n",
    "for feature in feature_importances[\n",
    "    (feature_importances['importance_means'] <= 0) & \n",
    "    (abs(feature_importances['importance_means']) >= feature_importances['importances_std'])\n",
    "].index:\n",
    "    # print(feature)\n",
    "    remove.append(feature)\n",
    "\n",
    "print(len(remove))\n",
    "remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96f8411",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in remove:\n",
    "    features.remove(feature)\n",
    "\n",
    "print(len(features))\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25954eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = all_data_df[features]\n",
    "y = mental_health_df['labels']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "nb_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('enc', OneHotEncoder(sparse=False, handle_unknown='ignore')), \n",
    "    ('red', PCA(n_components=10)),\n",
    "    ('clf', GaussianNB())\n",
    "])\n",
    "nb_pipe.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "nb_training_score = roc_auc_score(y_train.values, nb_pipe.predict_proba(X_train)[:, 1])\n",
    "nb_validation_score = roc_auc_score(y_val.values, nb_pipe.predict_proba(X_val)[:, 1])\n",
    "print(nb_training_score)\n",
    "nb_validation_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c360a826",
   "metadata": {},
   "source": [
    "### Round 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19ab2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = permutation_importance(\n",
    "    nb_pipe, \n",
    "    X_val, \n",
    "    y_val,\n",
    "    n_repeats=10,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "feature_importances = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        'importance_means': r['importances_mean'],\n",
    "        'importances_std': r['importances_std']\n",
    "    }, orient='columns'\n",
    ")\n",
    "feature_importances.index = X_val.columns\n",
    "\n",
    "#feature_importances.sort_values('importance_means', ascending = False)\n",
    "\n",
    "\n",
    "remove = []\n",
    "\n",
    "for feature in feature_importances[\n",
    "    (feature_importances['importance_means'] <= 0) & \n",
    "    (abs(feature_importances['importance_means']) >= feature_importances['importances_std'])\n",
    "].index:\n",
    "    # print(feature)\n",
    "    remove.append(feature)\n",
    "\n",
    "print(len(remove))\n",
    "remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ee0770",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in remove:\n",
    "    features.remove(feature)\n",
    "\n",
    "print(len(features))\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc468481",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = all_data_df[features]\n",
    "y = mental_health_df['labels']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "nb_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('enc', OneHotEncoder(sparse=False, handle_unknown='ignore')), \n",
    "    ('red', PCA(n_components=10)),\n",
    "    ('clf', GaussianNB())\n",
    "])\n",
    "nb_pipe.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "nb_training_score = roc_auc_score(y_train.values, nb_pipe.predict_proba(X_train)[:, 1])\n",
    "nb_validation_score = roc_auc_score(y_val.values, nb_pipe.predict_proba(X_val)[:, 1])\n",
    "print(nb_training_score)\n",
    "nb_validation_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2af0a2",
   "metadata": {},
   "source": [
    "### Round 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa5fb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = permutation_importance(\n",
    "    nb_pipe, \n",
    "    X_val, \n",
    "    y_val,\n",
    "    n_repeats=10,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "feature_importances = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        'importance_means': r['importances_mean'],\n",
    "        'importances_std': r['importances_std']\n",
    "    }, orient='columns'\n",
    ")\n",
    "feature_importances.index = X_val.columns\n",
    "\n",
    "#feature_importances.sort_values('importance_means', ascending = False)\n",
    "\n",
    "\n",
    "remove = []\n",
    "\n",
    "for feature in feature_importances[\n",
    "    (feature_importances['importance_means'] <= 0) & \n",
    "    (abs(feature_importances['importance_means']) >= feature_importances['importances_std'])\n",
    "].index:\n",
    "    # print(feature)\n",
    "    remove.append(feature)\n",
    "\n",
    "print(len(remove))\n",
    "remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857d22de",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in remove:\n",
    "    features.remove(feature)\n",
    "\n",
    "print(len(features))\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568e5485",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = all_data_df[features]\n",
    "y = mental_health_df['labels']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "nb_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('enc', OneHotEncoder(sparse=False, handle_unknown='ignore')), \n",
    "    ('red', PCA(n_components=10)),\n",
    "    ('clf', GaussianNB())\n",
    "])\n",
    "nb_pipe.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "nb_training_score = roc_auc_score(y_train.values, nb_pipe.predict_proba(X_train)[:, 1])\n",
    "nb_validation_score = roc_auc_score(y_val.values, nb_pipe.predict_proba(X_val)[:, 1])\n",
    "print(nb_training_score)\n",
    "nb_validation_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cc1b02",
   "metadata": {},
   "source": [
    "### Round 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c70185",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = permutation_importance(\n",
    "    nb_pipe, \n",
    "    X_val, \n",
    "    y_val,\n",
    "    n_repeats=10,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "feature_importances = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        'importance_means': r['importances_mean'],\n",
    "        'importances_std': r['importances_std']\n",
    "    }, orient='columns'\n",
    ")\n",
    "feature_importances.index = X_val.columns\n",
    "\n",
    "#feature_importances.sort_values('importance_means', ascending = False)\n",
    "\n",
    "\n",
    "remove = []\n",
    "\n",
    "for feature in feature_importances[\n",
    "    (feature_importances['importance_means'] <= 0) & \n",
    "    (abs(feature_importances['importance_means']) >= feature_importances['importances_std'])\n",
    "].index:\n",
    "    # print(feature)\n",
    "    remove.append(feature)\n",
    "\n",
    "print(len(remove))\n",
    "remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82696232",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in remove:\n",
    "    features.remove(feature)\n",
    "\n",
    "print(len(features))\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36083e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = all_data_df[features]\n",
    "y = mental_health_df['labels']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "nb_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('enc', OneHotEncoder(sparse=False, handle_unknown='ignore')), \n",
    "    ('red', PCA(n_components=10)),\n",
    "    ('clf', GaussianNB())\n",
    "])\n",
    "nb_pipe.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "nb_training_score = roc_auc_score(y_train.values, nb_pipe.predict_proba(X_train)[:, 1])\n",
    "nb_validation_score = roc_auc_score(y_val.values, nb_pipe.predict_proba(X_val)[:, 1])\n",
    "print(nb_training_score)\n",
    "nb_validation_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc205d47",
   "metadata": {},
   "source": [
    "### Round 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49ac2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = permutation_importance(\n",
    "    nb_pipe, \n",
    "    X_val, \n",
    "    y_val,\n",
    "    n_repeats=10,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "feature_importances = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        'importance_means': r['importances_mean'],\n",
    "        'importances_std': r['importances_std']\n",
    "    }, orient='columns'\n",
    ")\n",
    "feature_importances.index = X_val.columns\n",
    "\n",
    "#feature_importances.sort_values('importance_means', ascending = False)\n",
    "\n",
    "\n",
    "remove = []\n",
    "\n",
    "for feature in feature_importances[\n",
    "    (feature_importances['importance_means'] <= 0) & \n",
    "    (abs(feature_importances['importance_means']) >= feature_importances['importances_std'])\n",
    "].index:\n",
    "    # print(feature)\n",
    "    remove.append(feature)\n",
    "\n",
    "print(len(remove))\n",
    "remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc2bbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in remove:\n",
    "    features.remove(feature)\n",
    "\n",
    "print(len(features))\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cf8672",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = all_data_df[features]\n",
    "y = mental_health_df['labels']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "nb_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('enc', OneHotEncoder(sparse=False, handle_unknown='ignore')), \n",
    "    ('red', PCA(n_components=10)),\n",
    "    ('clf', GaussianNB())\n",
    "])\n",
    "nb_pipe.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "nb_training_score = roc_auc_score(y_train.values, nb_pipe.predict_proba(X_train)[:, 1])\n",
    "nb_validation_score = roc_auc_score(y_val.values, nb_pipe.predict_proba(X_val)[:, 1])\n",
    "print(nb_training_score)\n",
    "nb_validation_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1a20c9",
   "metadata": {},
   "source": [
    "### Round 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbebc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = permutation_importance(\n",
    "    nb_pipe, \n",
    "    X_val, \n",
    "    y_val,\n",
    "    n_repeats=10,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "feature_importances = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        'importance_means': r['importances_mean'],\n",
    "        'importances_std': r['importances_std']\n",
    "    }, orient='columns'\n",
    ")\n",
    "feature_importances.index = X_val.columns\n",
    "\n",
    "#feature_importances.sort_values('importance_means', ascending = False)\n",
    "\n",
    "\n",
    "remove = []\n",
    "\n",
    "for feature in feature_importances[\n",
    "    (feature_importances['importance_means'] <= 0) & \n",
    "    (abs(feature_importances['importance_means']) >= feature_importances['importances_std'])\n",
    "].index:\n",
    "    # print(feature)\n",
    "    remove.append(feature)\n",
    "\n",
    "print(len(remove))\n",
    "remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042f40b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in remove:\n",
    "    features.remove(feature)\n",
    "\n",
    "print(len(features))\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a1ea95",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = all_data_df[features]\n",
    "y = mental_health_df['labels']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "nb_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('enc', OneHotEncoder(sparse=False, handle_unknown='ignore')), \n",
    "    ('red', PCA(n_components=10)),\n",
    "    ('clf', GaussianNB())\n",
    "])\n",
    "nb_pipe.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "nb_training_score = roc_auc_score(y_train.values, nb_pipe.predict_proba(X_train)[:, 1])\n",
    "nb_validation_score = roc_auc_score(y_val.values, nb_pipe.predict_proba(X_val)[:, 1])\n",
    "print(nb_training_score)\n",
    "nb_validation_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
